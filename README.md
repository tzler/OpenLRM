# OpenLRM: Open-Source Large Reconstruction Models

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-yellow.svg)](LICENSE)
[![Weight License](https://img.shields.io/badge/Weight%20License-CC%20By%20NC%204.0-red)](LICENSE_WEIGHT)
[![LRM](https://img.shields.io/badge/LRM-Arxiv%20Link-green)](https://arxiv.org/abs/2311.04400)

[![HF Models](https://img.shields.io/badge/Models-Huggingface%20Models-bron)](https://huggingface.co/zxhezexin)
[![HF Demo](https://img.shields.io/badge/Demo-Huggingface%20Demo-blue)](https://huggingface.co/spaces/zxhezexin/OpenLRM)

### using LRM to generated novel viewpoints (inferred by dust3r) of experimental images

All custom function are in openlrm.datasets.cam_utils.py and openlrm.runners.infer.lrm.py. Modifications draw from viewpoints generated by dust3r to render experimental images from novel viewpoints.

### Inference on Trained Models 

This is the script I used to call LRM and generate renders for each trial in image_path: 

```
import subprocess
import numpy as np 

# script to call the relevant functions which generate image renders 
script = ("python -m openlrm.launch infer.lrm --infer './configs/infer-b.yaml' "
          "model_name='zxhezexin/openlrm-mix-base-1.1' image_input='%s' "
          "export_video=false export_mesh=false from_relative=true") 

# path to stimuli we're modeling
image_path = '/content/gdrive/MyDrive/perirhinal_function/configural/stimuli/barense'

# for each image, we generate novel images from all trial camera positions 
for i_imagename in np.sort( os.listdir(image_path) ): 

  # create a unique function all for this image
  i_script = script%os.path.join(image_path, i_imagename)

  # call and print the output in case anything went wrong
  print('\n', i_imagename, subprocess.check_output(i_script, shell=True)) 

  # everything is taken care of in custom functions in lrm.py and cam_utils.py

# determine where to move files to 
path_to_renders = '/content/gdrive/MyDrive/perirhinal_function/model_outputs/model_renders/'
# create new folder
os.makedirs(os.path.dirname(path_to_renders), exist_ok=True)
# move all files
os.system('cp -r dumps/relative_viewpoints/* %s'%(path_to_renders))

```

## Acknowledgement

- We thank the authors of the [original paper](https://arxiv.org/abs/2311.04400) for their great work! Special thanks to Kai Zhang and Yicong Hong for assistance during the reproduction.
- This project is supported by Shanghai AI Lab by providing the computing resources.
- This project is advised by Ziwei Liu and Jiaya Jia.

## Citation

```
@article{hong2023lrm,
  title={Lrm: Large reconstruction model for single image to 3d},
  author={Hong, Yicong and Zhang, Kai and Gu, Jiuxiang and Bi, Sai and Zhou, Yang and Liu, Difan and Liu, Feng and Sunkavalli, Kalyan and Bui, Trung and Tan, Hao},
  journal={arXiv preprint arXiv:2311.04400},
  year={2023}
}
```

```
@misc{openlrm,
  title = {OpenLRM: Open-Source Large Reconstruction Models},
  author = {Zexin He and Tengfei Wang},
  year = {2023},
  howpublished = {\url{https://github.com/3DTopia/OpenLRM}},
}
```

## License

- OpenLRM as a whole is licensed under the [Apache License, Version 2.0](LICENSE), while certain components are covered by [NVIDIA's proprietary license](LICENSE_NVIDIA). Users are responsible for complying with the respective licensing terms of each component.
- Model weights are licensed under the [Creative Commons Attribution-NonCommercial 4.0 International License](LICENSE_WEIGHT). They are provided for research purposes only, and CANNOT be used commercially.
